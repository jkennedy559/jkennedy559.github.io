{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "\n",
    "BJJ is my drug of choice and while I can't train in lockdown I'm watching alot old match videos. I was looking for results data from the most recent European Championships in the brown belt division. The IBJJF, the federation that run the major tournaments, release details of who medaled by belt & devision but provide no match level results. I decided to have a go at trying to programmatically piece results together."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly I did a recon on what was available. Flograppling have a subscription service that has video recordings of all matches from major competitions and I can subset matches by belt. I scraped these records and extracted competitor's names, match duration and a reference to the video's url. So I know all the brown matches that took place.\n",
    "\n",
    "Flograppling don't provide a breakdown by weight division but I did find registrations [here][1] from an IBJJF website and by joining on competitor name & belt I can map weight division to competitor. I can now have good go at classifying match winners and losers given I know the eventual division winners and can classify brackets with mapped competitor weights. \n",
    "\n",
    "[1]: https://www.ibjjfdb.com/ChampionshipResults/1415/PublicRegistrations?lang=en-US"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's a start but it would be great to get granular information.\n",
    "\n",
    "A match victor is decided by either points or submission. At brown belt matches last for a maximum of 8 minutes or until one competitor submits the other. From the video duration I already extracted I can tell if there has been a submission and I've already classified the winner & loser so I know who scored it.\n",
    "\n",
    "The match video has a scoreboard with the points scored by each competitor displayed so I signed up for a trial account at Flograppling and built a scraper [here][3] that logs in, watches the match video, pauses the video player with 5% of the match duration left to play and takes a screenshot.\n",
    "\n",
    "<img src=\"images/match_screen.png\" alt=\"Drawing\" style=\"width: 400px;\"/>\n",
    "\n",
    "I can crop the screenshot to extract the score board.\n",
    "\n",
    "<img src=\"visuals/scoreboard.png\" alt=\"Drawing\" style=\"width: 400px;\"/>\n",
    "\n",
    "I didn't fancy watching all 500 matches to manually label the score so I needed a method to programmatically extract the points scored from the screenshot. My first attempt involved Pytesseract but it didn't perform well. My next thought was to use a digit classification model.\n",
    "\n",
    "I found a convolutional neural network implemented with Tensorflow & Keras with > 99% test set accuracy trained on the MNIST dataset. If I process the cropped points images to be similar to the MNIST training examples the model should perform with similar accuracy.\n",
    "\n",
    "<img src=\"visuals/MNIST_example.png\" alt=\"Drawing\" style=\"width: 400px;\"/> \n",
    "<img src=\"visuals/cropped_points.png\" alt=\"Drawing\" style=\"width: 400px;\"/>  \n",
    "\n",
    "The MNIST dataset is preloaded in Tensorflow and a model training pipeline is provided in one of the example tutorials in the package documentation.\n",
    "\n",
    "I took a sample of 90 examples and manually labeled them on a csv to test the model. Not all the scraped screenshots captured the scoreboard adequately for classification and on one of 90 samples there was a double digit score so I excluded these which left me with 87 test examples.\n",
    "\n",
    "The model needs grayscale images with 28x28 resolution, digits must be roughly centered in white against a black background - I used OpenCV for this task. My first attempt at modeling used a binary threshold & image erosion to make the digits appear thiner against the black background.\n",
    "\n",
    "<img src=\"visuals/eroded_points.png\" alt=\"Drawing\" style=\"width: 400px;\"/> \n",
    "\n",
    "The model classified 85% correctly but was systemically misclassifying 6s as 5s.\n",
    "\n",
    "<img src=\"visuals/errors_cnn.png\" alt=\"Drawing\" style=\"width: 400px;\"/>\n",
    "\n",
    "In the end the best results I got involved just thresholding the cropped points image. The model misclassified one example and given three examples were excluded that's 86/90 correct. The notebook is available [here][2].\n",
    "\n",
    "<img src=\"visuals/final_classification.png\" alt=\"Drawing\" style=\"width: 400px;\"/>\n",
    "\n",
    "The model can't classify double digit scores, I would need an object parser to split each digit for classification separately. I amended the prediction threshold so the model only classifies when it's very certain, the remaining examples I resigned to label manually.\n",
    "\n",
    "Overall I'm happy this is a reasonable attempt at classifying matches, there will be some errors but it should get the vast majority correct.\n",
    "\n",
    "[2]: https://github.com/jkennedy559/bjj_data/blob/master/notebook.ipynb\n",
    "[3]: https://github.com/jkennedy559/bjj_data/blob/master/scrape.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
